{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tirumalanagasai/FMML_Project_and_Labs/blob/main/Fmml%20of_Module_01_Lab_01_Features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6I1yI79fbLD"
      },
      "source": [
        "# Extracting features from data\n",
        "\n",
        "FMML Module 1, Lab 1<br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OimBnfcpvcNS"
      },
      "source": [
        "! pip install wikipedia\n",
        "\n",
        "import wikipedia\n",
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import re\n",
        "import unicodedata\n",
        "import plotly.express as px\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6hGhIGiy4GP"
      },
      "source": [
        "# Part 1: Features of text\n",
        "How do we apply machine learning on text? We can't directly use the text as input to our algorithms. We need to convert them to features. In this notebook, we will explore a simple way of converting text to features.\n",
        "\n",
        "Let us download a few documents off Wikipedia."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpUmCoEr2R3J"
      },
      "source": [
        "topic1 = 'Giraffe'\n",
        "topic2 = 'Elephant'\n",
        "\n",
        "wikipedia.set_lang('en')\n",
        "\n",
        "eng1 = wikipedia.page(topic1).content\n",
        "eng2 = wikipedia.page(topic2).content\n",
        "\n",
        "wikipedia.set_lang('fr')\n",
        "\n",
        "fr1 = wikipedia.page(topic1).content\n",
        "fr2 = wikipedia.page(topic2).content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cj7RlhMiO5kd"
      },
      "source": [
        "This is what the text looks like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GW0G-t912UXZ"
      },
      "source": [
        "fr2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZkmNJ7XO9xX"
      },
      "source": [
        "We need to clean this up a bit. Let us remove all the special characters and keep only 26 letters and space. Note that this will remove accented characters in French also. We are also removing all the numbers and spaces. So this is not an ideal solution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5yf5P9pPI4t"
      },
      "source": [
        "def cleanup(text):\n",
        "  text = text.lower()  # make it lowercase\n",
        "  text = re.sub('[^a-z]+', '', text) # only keep characters\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrOjC32fRuTK"
      },
      "source": [
        "eng1 = cleanup(eng1)\n",
        "eng2 = cleanup(eng2)\n",
        "fr1 = cleanup(fr1)\n",
        "fr2 = cleanup(fr2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIdqvL2G-LqL"
      },
      "source": [
        "print(eng1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXFTWwd0rk63"
      },
      "source": [
        "Now let us calculate the frequency of the character n-grams. N-grams are groups of characters of size n. A unigram is a single character and a bigram is a group of two characters and so on.\n",
        "\n",
        "Let us count the frequency of each character in a text and plot it in a histogram."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3Lz3YUjN0L5"
      },
      "source": [
        "# convert a tuple of characters to a string\n",
        "def tuple2string(tup):\n",
        "  st = ''\n",
        "  for ii in tup:\n",
        "    st = st + ii\n",
        "  return st\n",
        "\n",
        "# convert a tuple of tuples to a list of strings\n",
        "def key2string(keys):\n",
        "  return [tuple2string(i) for i in keys]\n",
        "\n",
        "# plot the histogram\n",
        "def plothistogram(ngram):\n",
        "  keys = key2string(ngram.keys())\n",
        "  values = list(ngram.values())\n",
        "\n",
        "  # sort the keys in alphabetic order\n",
        "  combined = zip(keys, values)\n",
        "  zipped_sorted = sorted(combined, key=lambda x: x[0])\n",
        "  keys, values = map(list, zip(*zipped_sorted))\n",
        "  plt.bar(keys, values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHD62zbZcwAB"
      },
      "source": [
        "Let us compare the histograms of English pages and French pages. Can you spot a difference?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKcGRgH6b0KP"
      },
      "source": [
        "unigram_eng1 = Counter(ngrams(eng1,1))\n",
        "plothistogram(unigram_eng1)\n",
        "plt.title('English 1')\n",
        "plt.show()\n",
        "unigram_eng2 = Counter(ngrams(eng2,1))\n",
        "plothistogram(unigram_eng2)\n",
        "plt.title('English 2')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDM_UhCL2QLt"
      },
      "source": [
        "unigram_fr1 = Counter(ngrams(fr1,1))\n",
        "plothistogram(unigram_eng1)\n",
        "plt.title('French 1')\n",
        "plt.show()\n",
        "unigram_fr2 = Counter(ngrams(fr2,1))\n",
        "plothistogram(unigram_fr2)\n",
        "plt.title('French 2')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxgrdZLKdkAB"
      },
      "source": [
        "We can see that the unigrams for French and English are very similar. So this is not a good feature if we want to distinguish between English and French. Let us look at bigrams."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmRCxItx2T9W"
      },
      "source": [
        "bigram_eng1 = Counter(ngrams(eng1,2)) # bigrams\n",
        "plothistogram(bigram_eng1)\n",
        "plt.title('English 1')\n",
        "plt.show()\n",
        "\n",
        "bigram_eng2 = Counter(ngrams(eng2,2))\n",
        "plothistogram(bigram_eng2)\n",
        "plt.title('English 2')\n",
        "plt.show()\n",
        "\n",
        "bigram_fr1 = Counter(ngrams(fr1,2))\n",
        "plothistogram(bigram_eng1)\n",
        "plt.title('French 1')\n",
        "plt.show()\n",
        "\n",
        "bigram_fr2 = Counter(ngrams(fr2,2))\n",
        "plothistogram(bigram_fr2)\n",
        "plt.title('French 2')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-egsHMIg5Rp"
      },
      "source": [
        "Another way to visualize bigrams is to use a 2-dimensional graph."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EaPJgtaVxZM"
      },
      "source": [
        "def plotbihistogram(ngram):\n",
        "  freq = np.zeros((26,26))\n",
        "  for ii in range(26):\n",
        "    for jj in range(26):\n",
        "      freq[ii,jj] = ngram[(chr(ord('a')+ii), chr(ord('a')+jj))]\n",
        "  plt.imshow(freq, cmap = 'jet')\n",
        "  return freq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7jq3AwnVzQT"
      },
      "source": [
        "bieng1 = plotbihistogram(bigram_eng1)\n",
        "plt.show()\n",
        "bieng2 = plotbihistogram(bigram_eng2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXPTOj67WsPT"
      },
      "source": [
        "bifr1 = plotbihistogram(bigram_fr1)\n",
        "plt.show()\n",
        "bifr2 = plotbihistogram(bigram_fr2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGOEHcyGokD0"
      },
      "source": [
        "Let us look at the top 10 ngrams for each text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dk2TkzTno8vb"
      },
      "source": [
        "from IPython.core.debugger import set_trace\n",
        "\n",
        "def ind2tup(ind):\n",
        "  ind = int(ind)\n",
        "  i = int(ind/26)\n",
        "  j = int(ind%26)\n",
        "  return (chr(ord('a')+i), chr(ord('a')+j))\n",
        "\n",
        "def ShowTopN(bifreq, n=10):\n",
        "  f = bifreq.flatten()\n",
        "  arg = np.argsort(-f)\n",
        "  for ii in range(n):\n",
        "    print(f'{ind2tup(arg[ii])} : {f[arg[ii]]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HeWNh_q0QZ1"
      },
      "source": [
        "print('\\nEnglish 1:')\n",
        "ShowTopN(bieng1)\n",
        "print('\\nEnglish 2:')\n",
        "ShowTopN(bieng2)\n",
        "print('\\nFrench 1:')\n",
        "ShowTopN(bifr1)\n",
        "print('\\nFrench 2:')\n",
        "ShowTopN(bifr2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kDovOP4l98z"
      },
      "source": [
        "We observe that the bigrams are similar across different topics but different across languages. Thus, the bigram frequency is a good feature for distinguishing languages, but not for distinguishing topics.\n",
        "\n",
        "Thus, we were able to convert a many-dimensional input (the text) to 26 dimesions (unigrams) or 26*26 dimensions (bigrams).\n",
        "\n",
        "\n",
        "A few ways to explore:\n",
        "1. Try with different languages.\n",
        "2. The topics we used are quite similar, wikipedia articles of 'elephant' and 'giraffe'. What happens if we use very different topics? What if we use text from another source than Wikipedia?\n",
        "3. How can we use and visualize trigrams and higher n-grams?"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fl7eBb8Rouy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WF650rWqouc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Try with different languages: Experimenting with different languages is a great idea. You can gather text data from various languages and compute bigram frequencies to see how well they distinguish languages. Different languages have distinct grammatical structures and word usage patterns, which should reflect in their bigram frequencies.\n",
        "\n",
        "Use different topics or sources: Using different topics or sources can reveal how robust your bigram frequency approach is. If you choose topics that are very different from 'elephant' and 'giraffe', you may find that bigrams are still not effective for distinguishing topics. However, if you choose topics with highly specialized vocabularies or jargon, bigram frequencies might become more useful for topic classification. Additionally, using sources other than Wikipedia could introduce variations in writing styles and language, impacting the effectiveness of bigram features.\n",
        "\n",
        "Trigrams and higher n-grams: To use and visualize trigrams and higher n-grams, you can follow these steps:\n",
        "\n",
        "Compute trigram frequencies: Instead of analyzing pairs of adjacent words (bigrams), you can analyze triplets of adjacent words (trigrams) and higher n-grams (e.g., 4-grams, 5-grams). This can provide more context and capture more complex patterns in the text.\n",
        "\n",
        "Dimensionality reduction: Like you did with unigrams and bigrams, you can reduce the dimensionality of trigram or higher n-gram frequencies. You can use techniques like Principal Component Analysis (PCA) or t-SNE to visualize the data in lower dimensions.\n",
        "\n",
        "Visualization: Once you've reduced the dimensionality, you can create scatter plots or other visualization techniques to see if trigrams or higher n-grams can effectively distinguish between languages or topics. You may need to experiment with different visualization methods to find the most informative representation.\n",
        "\n",
        "Evaluate and compare: Finally, you should evaluate the performance of trigrams and higher n-grams in language or topic classification tasks and compare them with unigrams and bigrams. This will help you determine if they provide any additional insights or improvements.\n",
        "\n",
        "Remember that the effectiveness of n-grams (whether bigrams, trigrams, or higher) may vary depending on the specific task and dataset. It's essential to experiment and analyze the results to determine the most suitable approach for your particular use case.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KyJB2f6woauo"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZJfjIHk-oHV"
      },
      "source": [
        "# Part 2: Written numbers\n",
        "\n",
        "We will use a subset of the MNIST dataset. Each input character is represented in a 28*28 array. Let us see if we can extract some simple features from these images which can help us distinguish between the digits.\n",
        "\n",
        "Load the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNsLJSr6wGY0"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "#loading the dataset\n",
        "(train_X, train_y), (test_X, test_y) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVNr144WAUZO"
      },
      "source": [
        "Extract a subset of the data for our experiment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3MN8ddxAASZ"
      },
      "source": [
        "no1 = train_X[train_y==1,:,:]\n",
        "no0 = train_X[train_y==0,:,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePXCs0qyCLpc"
      },
      "source": [
        "Let us visualize a few images here:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQeyZSh-Arpc"
      },
      "source": [
        "for ii in range(5):\n",
        "  plt.subplot(1, 5, ii+1)\n",
        "  plt.imshow(no1[ii,:,:])\n",
        "plt.show()\n",
        "for ii in range(5):\n",
        "  plt.subplot(1, 5, ii+1)\n",
        "  plt.imshow(no0[ii,:,:])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1g-Tg7EKDz96"
      },
      "source": [
        "suNow, let us start with a simple feature: the sum of all pixels and see how good this feature is."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8SztDk7CyZc"
      },
      "source": [
        "sum1 = np.sum(no1>0, (1,2)) # threshold before adding up\n",
        "sum0 = np.sum(no0>0, (1,2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oW3XCOCE7Zv"
      },
      "source": [
        "Let us visualize how good this feature is: (X-axis is mean, y-axis is the digit)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8PIe8o_DPpU"
      },
      "source": [
        "plt.hist(sum1, alpha=0.7);\n",
        "plt.hist(sum0, alpha=0.7);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_hToEepFtl2"
      },
      "source": [
        "We can already see that this feature separates the two classes quite well.\n",
        "\n",
        "Let us look at another, more complicated feature. We will count the number black pixels that are surrounded on four sides by non-black pixels, or \"hole pixels\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwEnlm6RFFej"
      },
      "source": [
        "def cumArray(img):\n",
        "  img2 = img.copy()\n",
        "  for ii in range(1, img2.shape[1]):\n",
        "    img2[ii,:] = img2[ii,:] + img2[ii-1,:]  # for every row, add up all the rows above it.\n",
        "  img2 = img2>0\n",
        "  return img2\n",
        "\n",
        "def getHolePixels(img):\n",
        "  im1 = cumArray(img)\n",
        "  im2 = np.rot90(cumArray(np.rot90(img)), 3) # rotate and cumulate it again for differnt direction\n",
        "  im3 = np.rot90(cumArray(np.rot90(img, 2)), 2)\n",
        "  im4 = np.rot90(cumArray(np.rot90(img, 3)), 1)\n",
        "  hull =  im1 & im2 & im3 & im4 # this will create a binary image with all the holes filled in.\n",
        "  hole = hull & ~ (img>0) # remove the original digit to leave behind the holes\n",
        "  return hole"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iw3HjgnupUEI"
      },
      "source": [
        "Visualize a few:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0sjr23NYEFe"
      },
      "source": [
        "imgs = [no1[456,:,:],  no0[456,:,:]]\n",
        "for img in imgs:\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.imshow(getHolePixels(img))\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.imshow(img)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vS-4erNXtxMi"
      },
      "source": [
        "Now let us plot the number of hole pixels and see how this feature behaves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dpm1dRgsety8"
      },
      "source": [
        "hole1 = np.array([getHolePixels(i).sum() for i in no1])\n",
        "hole0 = np.array([getHolePixels(i).sum() for i in no0])\n",
        "\n",
        "plt.hist(hole1, alpha=0.7);\n",
        "plt.hist(hole0, alpha=0.7);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UjCBHpJ31yq"
      },
      "source": [
        "This feature works even better to distinguish between one and zero.\n",
        "\n",
        "\n",
        "Now let us try the number of pixels in the 'hull' or the number with the holes filled in:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPtJ8eqolAOf"
      },
      "source": [
        "def getHullPixels(img):\n",
        "  im1 = cumArray(img)\n",
        "  im2 = np.rot90(cumArray(np.rot90(img)), 3) # rotate and cumulate it again for differnt direction\n",
        "  im3 = np.rot90(cumArray(np.rot90(img, 2)), 2)\n",
        "  im4 = np.rot90(cumArray(np.rot90(img, 3)), 1)\n",
        "  hull =  im1 & im2 & im3 & im4 # this will create a binary image with all the holes filled in.\n",
        "  return hull"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3fOgyYjmJ48"
      },
      "source": [
        "imgs = [no1[456,:,:],  no0[456,:,:]]\n",
        "for img in imgs:\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.imshow(getHullPixels(img))\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.imshow(img)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5rHal_HRWnE"
      },
      "source": [
        "Plotting the number of hull pixels versus the digit:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTLzYZLTRQ_p"
      },
      "source": [
        "hull1 = np.array([getHullPixels(i).sum() for i in no1])\n",
        "hull0 = np.array([getHullPixels(i).sum() for i in no0])\n",
        "\n",
        "plt.hist(hull1, alpha=0.7);\n",
        "plt.hist(hull0, alpha=0.7);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSzH26ElXNri"
      },
      "source": [
        "Let us try one more feature, where we look at the number of boundary pixels in each image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-2czBypXMwT"
      },
      "source": [
        "def minus(a, b):\n",
        "  return a & ~ b\n",
        "\n",
        "def getBoundaryPixels(img):\n",
        "  img = img.copy()>0  # binarize the image\n",
        "  rshift = np.roll(img, 1, 1)\n",
        "  lshift = np.roll(img, -1 ,1)\n",
        "  ushift = np.roll(img, -1, 0)\n",
        "  dshift = np.roll(img, 1, 0)\n",
        "  boundary = minus(img, rshift) | minus(img, lshift) | minus(img, ushift) | minus(img, dshift)\n",
        "  return boundary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-V688jFerXh"
      },
      "source": [
        "imgs = [no1[456,:,:],  no0[456,:,:]]\n",
        "for img in imgs:\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.imshow(getBoundaryPixels(img))\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.imshow(img)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSsxsbCNXcNh"
      },
      "source": [
        "bound1 = np.array([getBoundaryPixels(i).sum() for i in no1])\n",
        "bound0= np.array([getBoundaryPixels(i).sum() for i in no0])\n",
        "\n",
        "plt.hist(bound1, alpha=0.7);\n",
        "plt.hist(bound0, alpha=0.7);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuP04Ao_R0Yz"
      },
      "source": [
        "What will happen if we plot two features together?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kl7xWg-WRkAy"
      },
      "source": [
        "# Sum and hull\n",
        "plt.scatter(sum0, hull0, alpha=0.1)\n",
        "plt.scatter(sum1, hull1, alpha=0.1)\n",
        "plt.xlabel('Sum')\n",
        "plt.ylabel('Hull')\n",
        "plt.legend(['0','1'])\n",
        "plt.show()\n",
        "\n",
        "# Sum and hole\n",
        "plt.scatter(sum0, hole0, alpha=0.1)\n",
        "plt.scatter(sum1, hole1, alpha=0.1)\n",
        "plt.xlabel('Sum');\n",
        "plt.ylabel('Hole');\n",
        "plt.legend(['0','1'])\n",
        "plt.show()\n",
        "\n",
        "# Hole and boundary\n",
        "plt.scatter(bound0, hole0, alpha=0.1)\n",
        "plt.scatter(bound1, hole1, alpha=0.1)\n",
        "plt.xlabel('Boundary');\n",
        "plt.ylabel('Hole');\n",
        "plt.legend(['0','1'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JYLmKNFSIT-"
      },
      "source": [
        "Now let us try plotting 3 features together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOKEHIXFaWp_"
      },
      "source": [
        "cl1 = ['class 1']*len(sum1)\n",
        "cl0 = ['class 0']*len(sum0)\n",
        "df = pd.DataFrame(list(zip(np.concatenate((hole0, hole0)), np.concatenate((sum1,sum0)),\n",
        "                           np.concatenate((bound1,bound0)), np.concatenate((cl1, cl0)))),\n",
        "               columns =['Hole', 'Sum', 'Boundary', 'Class'])\n",
        "df.head()\n",
        "fig = px.scatter_3d(df, x='Hole', y='Sum', z='Boundary', color='Class', opacity=0.1)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paDGHlFSd5Fu"
      },
      "source": [
        "Feel free to explore the above graph with your mouse.\n",
        "\n",
        "\n",
        "We have seen that we extracted four features from a 28*28 dimensional image.\n",
        "\n",
        "\n",
        "Some questions to explore:\n",
        "1. Which is the best combination of features?\n",
        "2. How would you test or visualize four or more features?\n",
        "3. Can you come up with your own features?\n",
        "4. Will these features work for different classes other than 0 and 1?\n",
        "5. What will happen if we take more that two classes at a time?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 . Relevance to the Problem: Features should be relevant to the problem you're trying to solve. Features that do not carry meaningful information about the target variable should be removed.\n",
        "\n",
        "Redundancy: Avoid including highly correlated features, as they can introduce multicollinearity issues and make the model less interpretable.\n",
        "\n",
        "Dimensionality: High-dimensional data can lead to overfitting and increased computational complexity. Feature selection or dimensionality reduction techniques like Principal Component Analysis (PCA) can help.\n",
        "\n",
        "Domain Knowledge: Incorporate domain knowledge whenever possible. Subject-matter experts may provide valuable insights into which features are likely to be important.\n",
        "\n",
        "Feature Importance: You can use feature importance scores from machine learning algorithms like decision trees or random forests to rank features. This can help you identify the most influential features.\n",
        "\n",
        "Feature Engineering: Sometimes, creating new features or transforming existing ones can improve model performance. This might involve combining features, scaling, or applying mathematical functions.\n",
        "\n",
        "Regularization: Techniques like L1 regularization (Lasso) can automatically select important features while setting others to zero.\n",
        "\n",
        "Cross-Validation: Use cross-validation to assess the performance of different feature combinations. This helps you avoid overfitting and gives you an idea of how well your model generalizes.\n",
        "\n",
        "Iterative Process: Feature selection is often an iterative process. You can start with a set of features, build models, evaluate performance, and then adjust the feature set based on the results.\n",
        "\n",
        "Ensemble Methods: Some ensemble methods like Random Forests can handle a large number of features and provide insights into feature importance.\n",
        "\n",
        "Feature Scaling: Ensure that features are on a similar scale, especially when using distance-based algorithms like k-Nearest Neighbors or clustering methods.\n",
        "\n",
        "2 . Pairwise Scatter Plots (Matrix Scatter Plot):\n",
        "\n",
        "Create a matrix of scatter plots, where each combination of two features is plotted against each other. If you have four features, this would result in six scatter plots. Use color or shape to represent the values of a fifth or sixth feature if necessary. Libraries like Seaborn in Python make it relatively easy to create pair plots. Parallel Coordinates Plot:\n",
        "\n",
        "This plot is suitable for visualizing multivariate data. Each feature is represented as a vertical axis, and lines connect data points based on their values for each feature. Patterns in the lines can reveal relationships between the features. You can use libraries like Matplotlib or specialized packages like plotly to create parallel coordinates plots. 3D Scatter Plots with Color Mapping:\n",
        "\n",
        "If you have four features and a target variable (e.g., classification labels or regression values), you can create a 3D scatter plot where three features define the x, y, and z coordinates, and the fourth feature can be represented using color or size of the markers. Matplotlib and Plotly can help create 3D scatter plots. Ternary Plots or Triangle Plots:\n",
        "\n",
        "If your features are constrained to sum to a constant (e.g., three chemical components that sum to 100%), you can use ternary plots. Each point inside the triangle represents a combination of the three features, and the position within the triangle indicates the relative proportions. You can use libraries like matplotlib-ternary in Python to create ternary plots. Dimensionality Reduction:\n",
        "\n",
        "Techniques like Principal Component Analysis (PCA) or t-Distributed Stochastic Neighbor Embedding (t-SNE) can reduce the dimensionality of your data while preserving important information. You can visualize the data in a lower-dimensional space (e.g., 2D or 3D) after applying these methods. Heatmaps and Correlation Matrices:\n",
        "\n",
        "Create a heatmap of the correlation matrix between all features. This can help identify patterns and relationships between features, especially if some are highly correlated. Python libraries like Seaborn and Matplotlib are commonly used for creating heatmaps. Interactive Visualizations:\n",
        "\n",
        "Interactive visualizations can be very useful for exploring high-dimensional data. Tools like Plotly, Bokeh, or Tableau allow you to create interactive plots where you can zoom, pan, and highlight data points to gain insights.\n",
        "\n",
        "3 . Polynomial Features: You can generate polynomial features by raising existing features to different powers (e.g., squaring or cubing them). This can capture nonlinear relationships between features and the target variable.\n",
        "\n",
        "Interactions: Create interaction features by combining two or more existing features. For example, if you have features for length and width, you can create a new feature representing area by multiplying these two features.\n",
        "\n",
        "Aggregations: Compute summary statistics like mean, median, minimum, maximum, or standard deviation for groups of data points based on a categorical feature. This can be useful for turning time-series data or categorical data into meaningful numeric features.\n",
        "\n",
        "Time-Based Features: If you're working with time-series data, you can extract various time-related features such as day of the week, month, season, or time elapsed since a specific event.\n",
        "\n",
        "Text-Based Features: When dealing with text data, you can engineer features such as word counts, character counts, TF-IDF scores, or sentiment scores to represent the text content.\n",
        "\n",
        "Encoding Categorical Variables: Convert categorical variables into numerical format using techniques like one-hot encoding, label encoding, or target encoding.\n",
        "\n",
        "Binning or Discretization: Group numerical values into bins or categories. For example, you can convert age into age groups (e.g., \"child,\" \"teen,\" \"adult,\" \"senior\").\n",
        "\n",
        "Domain-Specific Features: Leverage domain knowledge to create features that are specific to your problem. These features may not be immediately apparent in the raw data but can capture important patterns or relationships.\n",
        "\n",
        "Geospatial Features: If working with geospatial data, you can engineer features like distances between locations, clustering of data points, or geospatial statistics\n",
        "\n",
        "Combining Features: Combine multiple features in creative ways to create composite features that may capture complex relationships in the data.\n",
        "\n",
        "Feature Scaling and Normalization: Standardize or normalize features to bring them to a common scale. This can be important for algorithms sensitive to feature scales, like many machine learning algorithms.\n",
        "\n",
        "Feature Selection: While this involves choosing the most relevant features rather than creating new ones, it's still an essential part of feature engineering. Techniques like Recursive Feature Elimination (RFE) can help identify the most informative features\n",
        "\n",
        "4 . Multi-Class Labels: Ensure that your target variable has multiple classes (more than just 0 and 1) representing different categories or labels. Multi-class classification problems involve classifying data points into one of several possible classes.\n",
        "\n",
        "Feature Engineering Principles: The principles of feature engineering remain the same regardless of the number of classes. You can create new features, transform existing ones, and preprocess the data to better capture relationships and patterns that help distinguish between different classes.\n",
        "\n",
        "Encoding Multi-Class Labels: You may need to encode your multi-class labels appropriately. Common encoding methods include one-hot encoding (creating binary columns for each class), label encoding (assigning a unique integer to each class), or ordinal encoding (if classes have a natural order).\n",
        "\n",
        "Feature Importance and Interpretation: When working with multiple classes, it's still essential to understand which features are most important for distinguishing between the classes. You can use techniques like feature importance scores from random forests or gradient boosting models to assess feature importance.\n",
        "\n",
        "Visualization: Visualizing multi-class data can be more challenging than binary data, but techniques such as dimensionality reduction (e.g., PCA or t-SNE) can help you visualize the data in a lower-dimensional space while preserving class information.\n",
        "\n",
        "Validation and Evaluation: Ensure you use appropriate metrics for evaluating multi-class classification models. Common metrics include accuracy, precision, recall, F1-score, and confusion matrices.\n",
        "\n",
        "Imbalanced Classes: In multi-class scenarios, you may encounter imbalanced class distributions. Feature engineering can also help address class imbalance by creating informative features or using techniques like Synthetic Minority Over-sampling Technique (SMOTE).\n",
        "\n",
        "Domain Knowledge: As with any feature engineering task, domain knowledge is valuable for understanding the data and creating features that are relevant to the problem at hand, whether it's multi-class classification or another task.\n",
        "\n",
        "5 . Increased Complexity: Multi-class classification is inherently more complex than binary classification because there are multiple classes to consider. The model must learn to differentiate between all the available classes, not just two.\n",
        "\n",
        "Class Imbalance: Class imbalance is often more pronounced in multi-class problems, as some classes may have more instances than others. This can affect model training and evaluation, and you may need to address class imbalance with techniques like over-sampling, under-sampling, or class-weighted models.\n",
        "\n",
        "Classification Algorithms: Many classification algorithms can naturally handle multi-class problems, including decision trees, random forests, support vector machines, and neural networks. These algorithms can be used directly without modification.\n",
        "\n",
        "One-vs-All (OvA) or One-vs-One (OvO): Some algorithms, like logistic regression or binary support vector machines, need adaptations to handle multi-class problems. Common approaches include OvA (also known as one-hot encoding) and OvO, where multiple binary classifiers are trained to distinguish between pairs of classes.\n",
        "\n",
        "Evaluation Metrics: In multi-class classification, you'll use different evaluation metrics than in binary classification. Common metrics include accuracy, precision, recall, F1-score, confusion matrices, and multi-class log-loss (cross-entropy).\n",
        "\n",
        "Output Probability Distribution: For each data point, multi-class models output a probability distribution over all classes. The class with the highest probability is the predicted class. This allows you to assess model confidence and explore class probabilities for uncertainty estimation.\n",
        "\n",
        "Visualization Challenges: Visualizing the performance and results of multi-class classification can be more challenging than binary classification. Techniques like confusion matrices can help, and dimensionality reduction can aid in visualization.\n",
        "\n",
        "Feature Engineering: Feature engineering and data preprocessing remain essential, but you might need to consider how different features relate to multiple classes simultaneously. Feature engineering can involve creating new features that capture multi-class relationships.\n",
        "\n",
        "Cross-Validation: Cross-validation is crucial for assessing the model's performance in a multi-class setting. Techniques like k-fold cross-validation should be used to ensure robust evaluation.\n",
        "\n",
        "Hyperparameter Tuning: Tuning hyperparameters is an important step, and you may need to optimize the model parameters to achieve the best performance.\n"
      ],
      "metadata": {
        "id": "omqU7TGXn2hh"
      }
    }
  ]
}